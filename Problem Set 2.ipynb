{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 0\n",
    "\n",
    "def github() -> str:\n",
    "    \"\"\"\n",
    "    This function will return Bani Bedi's GitHub page for Problem Set 2.\n",
    "    \"\"\"\n",
    "\n",
    "    return \"https://github.com/banibedi/Econ481.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ -6.51860921],\n",
       "        [  6.33118699],\n",
       "        [ 12.83313575],\n",
       "        ...,\n",
       "        [  7.33718628],\n",
       "        [-11.31573378],\n",
       "        [-15.97084066]]),\n",
       " array([[-1.66963192e+00,  1.37207744e-01, -7.30136762e-01],\n",
       "        [-4.41173815e+00,  2.23326705e+00,  2.08386262e+00],\n",
       "        [-2.40310680e-01,  4.18363715e+00,  4.31683643e-01],\n",
       "        ...,\n",
       "        [-3.09088232e+00,  2.07184737e-03,  1.99127529e+00],\n",
       "        [-1.42508829e+00, -6.21390539e-01, -1.74262094e+00],\n",
       "        [ 3.24670128e-01, -9.58730162e-01, -3.28090476e+00]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 1\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def simulate_data(seed: int) -> tuple: # Defining the function 'simulate_data' that contains integers and will return a tuple\n",
    "    \"\"\"\n",
    "    This function returns 1000 simulated observations using this process: y = 5 + 3x_{i1} + 2x_{i2} + 6x_{i3} +  y_i epsilon_i.\n",
    "    The independent variables are drawn from a normal distribution with a mean of 0 and a standard deviation of 2.\n",
    "    The error term is drawn from a normal distribution with a mean of 0 and a standard deviation of 1. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the seed to regenerate results for random processes\n",
    "\n",
    "    np.random.seed(seed = 481) # Set the 481 like stated in the assignment\n",
    "\n",
    "    # Generate the independent variables (x_{i1}. x_{i2}. x_{i3})\n",
    "\n",
    "    x = np.random.normal(0, 2, size = (1000, 3)) # The equation is standard normal; the mean is 0 and the standard deviation is 2; this array is 1000 x 3\n",
    "\n",
    "    # Generate the error term\n",
    "\n",
    "    E = np.random.normal(0, 1, size = (1000, 1)) # This equation is standard normal; the mean is 0 and standard deviation is 1; the array is 1000 x 1\n",
    "\n",
    "    # Calculate 'y' value of the equation (for all 1000 observations)\n",
    "\n",
    "    y = 5 + 3*x[:, 0] + 2*x[:,1] + 6*x[:, 2] + E # Rewrite equation in python; this takes all 1000 values for the corresponding column and multiply it by the corresponding value (i.e. takes all 1000 values of the first column of x_{i1} and mutiplies it by 3); add error term in model too\n",
    "\n",
    "    # Reshape y to be a 1000 x 1 array\n",
    "\n",
    "    y = y.reshape(-1, 1) # Change shape of array using reshape from 1D to 2D; ; since we do not know / want to explictly tell the dimension of that axis, we reshape with (-1, 1) so the array only has 1 column\n",
    "\n",
    "    return y, x # Return a tuple containing the array of y values and a matrix of x values\n",
    "\n",
    "# Call the function simulate_data\n",
    "\n",
    "simulate_data(seed = 481) # Seed is set to 481 like stated in the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.97696956]\n",
      " [3.00284624]\n",
      " [2.07127613]\n",
      " [3.97733055]]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "\n",
    "import numpy as np \n",
    "# Since this is a closed-form function, scipy.optimize isn't necessarily needed\n",
    "\n",
    "def estimate_mle(y: np.array, X: np.array) -> np.array: # Defines function 'estimate_mle' and states that 'y' and 'X' are arrays and the result will also be an array\n",
    "    \"\"\"\n",
    "    This function estimates the MLE parameters (B_hat{MLE}) where the assumed model is y{1} = B{0} + B{1}x_{i1} + B{2}x_{i2} + B{3}x_{i3} + E{i}.\n",
    "    The error term E{i} is normally distributed with a mean of 0 and a standard error of 1.\n",
    "    It takes a 1000 x 1 'y' array and 1000 x 3 'x' array and returns a 4 x 1 array with coefficients B{0}, B{1}, B{2}, and B{3} in that order.\n",
    "    \"\"\"\n",
    "\n",
    "    # Note: If error term is normally distributed, the MLE approach will obtain the same estimates as those obtained from OLS \n",
    "\n",
    "    # Add the intercept function B{0}\n",
    "\n",
    "    X_int = np.hstack((np.ones((X.shape[0], 1)), X)) # Defining the intercept B{0}; np.ones creates a vector of 1000 x 1 (aka the number of rows in the matrix), and every element in this column is 1; hstack puts the two matrices and sticks them horizontally \n",
    "        # Each row is an observation with the first number being '1'\n",
    "\n",
    "    # Compute the OLS estimates for regression coefficients\n",
    "\n",
    "    beta_hat = np.linalg.inv(X_int.T @ X_int) @ X_int.T @ y # Transposes X_int and multiply both X_int and X_int.T; calculate the inverse of the matrix with np.linalg.inv; multiply again by X_int.T; multiply again by y\n",
    "\n",
    "    # Return the parameter estimates    \n",
    "        \n",
    "    return beta_hat.reshape(-1, 1) # Like the previous question, reshape the array to calculate the number of rows in beta_hat (hence the -1) with one column\n",
    "\n",
    "# Test\n",
    "\n",
    "# Setting the seed\n",
    "\n",
    "np.random.seed(481) # Set default seed to ensure the same random values for consistency\n",
    "\n",
    "# Simulate the independent variables (X)\n",
    "\n",
    "X = np.random.normal(0, 1, (1000, 3)) # Set the X variable to a normal distribution with a mean of 0 and a standard deviation of 1; the array will be 1000 x 3\n",
    "\n",
    "# Define all beta values\n",
    "\n",
    "beta_values = np.array([6, 3, 2, 4]) # Create sample beta values\n",
    "\n",
    "# Simulate error term\n",
    "\n",
    "E = np.random.normal(0, 1, (1000, 1)) # Set the error term to a normal distrubution with a mean of 0 and a standard deviation of 1; the array will be 1000 x 1; this is based on given information from the assignment\n",
    "\n",
    "# Calculate 'y' variable\n",
    "\n",
    "y = np.hstack((np.ones((1000, 1)), X)) @ beta_values[:, None] + E # Calculates 'y' similar to prior problem; horizontally stacks the 1000 x 1 columns with matrix X; then multiplies with beta values; adds error term after\n",
    "\n",
    "# Estimate MLE Parameters\n",
    "\n",
    "estimated_parameters = estimate_mle(y, X) # This will return the estimate of the parameters of the model based on simulated 'y' and 'X'\n",
    "print(estimated_parameters) # Return estiamted paramters in 4 x 1 format like assignment stated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9764274 ]\n",
      " [2.        ]\n",
      " [3.00000001]\n",
      " [4.00000001]]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "\n",
    "import numpy as np \n",
    "from scipy.optimize import minimize # Minimize RSS using scipy.optimize.minimize\n",
    "    \n",
    "def estimate_ols(y: np.array, X: np.array) -> np.array: # Defines the 'estimate_ols' function, stating that both the 'X' and 'y' variables are an array and the result will also be an array\n",
    "    \"\"\"\n",
    "    This function estinates the OLS coefficients for the simulated data without using the closed form solution.\n",
    "    It takes a 1000 x 1 'y' array and 1000 x 3 'x' array and returns a 4 x 1 array with coefficients B{0}, B{1}, B{2}, and B{3} in that order.\n",
    "    \"\"\"\n",
    "\n",
    "# Use an optimization technique to minimize the residual sum of squares (sum of squared of observed values vs. values predicted by the model)\n",
    "    \n",
    "# Define cost function that calculates residual sum of squares\n",
    "    # The goal is to find a set of beta coefficients that makes our model's predictions as close to the observed data as possible (RSS)\n",
    "\n",
    "    def cost_function(beta, X, y): # Defines the 'cost function' that includes three arguments: beta, X, and y\n",
    "        y_estimated = X @ beta # Calculates the predicted value of 'y' by  multiplying 'X' by 'beta'; \n",
    "        residuals = y - y_estimated # After obtaining the predicted values, calculate the difference between the observed values and values generated by the model\n",
    "        sum_sq = np.sum(residuals ** 2) # Penalizes larger errors more severely than smaller ones; they are then summed up to represent the total error of the model's predictions\n",
    "        return sum_sq\n",
    "        \n",
    "# Use scipy.optimize functions to find parameters that minimize this cost function\n",
    "    \n",
    "    X_int = np.hstack((np.ones((X.shape[0], 1)), X)) # Defines X-intercept; takes 1000 x 1 matrix, includes 1 as the first number, and stacks it up horizontally; then makes the array as big as 'X\"\n",
    "    beta_i = np.zeros(X_int.shape[1]) # Initializes starting point with vector of zeros; includes intercept and slope of each variable\n",
    "    result = minimize(fun=cost_function, x0 = beta_i, args=(X_int, y)) # Minimizes cost function; sets initial guess of coefficients; provides both variable arguments\n",
    "    return result.x.reshape(-1, 1)    \n",
    "\n",
    "# Test\n",
    "\n",
    "# Setting the seed\n",
    "\n",
    "np.random.seed(481) # Set default seed to ensure the same random values for consistency\n",
    "\n",
    "# Simulate the independent variables (X)\n",
    "\n",
    "X = np.random.normal(0, 1, (1000, 3)) # Set the X variable to a normal distribution with a mean of 0 and a standard deviation of 1; the array will be 1000 x 3\n",
    "\n",
    "# Sample values\n",
    "\n",
    "sample_coef = np.array([1, 2, 3, 4])  # Sample coefficient\n",
    "intercept_column = np.ones((1000, 1))  # Intercept term\n",
    "X_with_intercept = np.hstack((intercept_column, X))  # Add intercept term to the matrix of independent variables\n",
    "y = X_with_intercept @ sample_coef + np.random.normal(0, 1, (1000, 1))  # 'y' variable\n",
    "\n",
    "# Result\n",
    "\n",
    "estimated_parameters = estimate_ols(y, X)\n",
    "print(estimated_parameters) # Result is very close to actual values (success!)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
